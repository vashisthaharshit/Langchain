{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/LLM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/LLM.pdf', 'page': 0}, page_content='Original Investigation| Statistics and Research Methods\\nPerformance of a Large Language Model in Screening Citations\\nTakehikoOami,MD,PhD;YoheiOkada,MD,PhD;Taka-akiNakada,MD,PhD\\nAbstract\\nIMPORTANCE Largelanguagemodels(LLMs)arepromisingastoolsforcitationscreeningin\\nsystematicreviews.H owever,theirapplicabilityhasnotyetbeendetermined.\\nOBJECTIVE ToevaluatetheaccuracyandefficiencyofanLLMintitleandabstractliterature\\nscreening.\\nDESIGN, SETTING, AND PARTICIPANTSThisprospectivediagnosticstudyusedthedatafromthe\\ntitleandabstractscreeningprocessfor5clinicalquestions(CQs)inthedevelopmentoftheJapanese\\nClinicalPracticeGuidelinesforManagementofSepsisandSepticShock.TheLLMdecidedtoinclude\\norexcludecitationsbasedontheinclusionandexclusioncriteriaintermsofpatient,population,\\nproblem;intervention;comparison;andstudydesignoftheselectedCQandwascomparedwiththe\\nconventionalmethodfortitleandabstractscreening.ThisstudywasconductedfromJanuary7to\\n15,2024.\\nEXPOSURES LLM(GPT-4Turbo)–assistedcitationscreeningortheconventionalmethod.\\nMAIN OUTCOMES AND MEASURESThesensitivityandspecificityoftheLLM-assistedscreening\\nprocesswascalculated,andthefull-textscreeningresultusingtheconventionalmethodwassetas\\nthereferencestandardintheprimaryanalysis.Pooledsensitivityandspecificitywerealsoestimated,\\nandscreeningtimesofthe2methodswerecompared.\\nRESULTS Intheconventionalcitationscreeningprocess,8of5634publicationsinCQ1,4of3418in\\nCQ2,4of1038inCQ3,17of4326inCQ4,and8of2253inCQ5wereselected.Intheprimary\\nanalysisof5CQs,LLM-assistedcitationscreeningdemonstratedanintegratedsensitivityof0.75\\n(95%CI,0.43to0.92)andspecificityof0.99(95%CI,0.99to0.99).Posthocmodificationstothe\\ncommandpromptimprovedtheintegratedsensitivityto0.91(95%CI,0.77to0.97)without\\nsubstantiallycompromisingspecificity(0.98[95%CI,0.96to0.99]).Additionally,LLM-assisted\\nscreeningwasassociatedwithreducedtimeforprocessing100studies(1.3minutesvs17.2minutes\\nforconventionalscreeningmethods;meandifference,−15.25minutes[95%CI,−17.70to−12.79\\nminutes]).\\nCONCLUSIONS AND RELEVANCEInthisprospectivediagnosticstudyinvestigatingthe\\nperformanceofLLM-assistedcitationscreening,themodeldemonstratedacceptablesensitivityand\\nreasonablyhighspecificitywithreducedprocessingtime.Thisnovelmethodcouldpotentially\\nenhanceefficiencyandreduceworkloadinsystematicreviews.\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496\\nKey Points\\nQuestion Howaccurateandefficientis\\nalargelanguagemodel(LLM)for\\nscreeningtitlesandabstractsforarticle\\ninclusioninasystematicreview?\\nFindings Inthisdiagnosticstudy,\\nLLM-assistedcitationscreening\\nexhibitedacceptablesensitivityand\\nreasonablyhighspecificityinevaluating\\n5clinicalquestions,withposthoc\\npromptmodificationsfurtherimproving\\naccuracy.Thescreeningtimefor100\\nstudieswassignificantlyreduced\\ncomparedwiththatof\\nconventionalmethods.\\nMeaning Thesefindingssuggestthat\\nLLM-assistedcitationscreeningcould\\nofferareliableandtime-efficient\\nalternativetosystematicreview\\nprocesses.\\n+ Supplemental content\\nAuthoraffiliationsandarticleinformationare\\nlistedattheendofthisarticle.\\nOpen Access.ThisisanopenaccessarticledistributedunderthetermsoftheCC-BYLicense.\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 1/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 1}, page_content='Introduction\\nClinicalpracticeguidelinesaresystematicallydevelopedbasedonasynthesisofthecurrentbest\\nevidenceandprovidecliniciansandpatientswithessentialguidanceforclinicaldecision-making.\\nDuringguidelinedevelopment,collectingandcompilingthelatestresearchfindingsinsystematic\\nreviewsisacriticalprocessrequiringextensiveworkandeffortforscreeningtherelevantliterature,\\ntherebypresentingamajorchallengeinthedevelopmentofsuchguidelines.1-3Recentprogressin\\napplyingmachinelearningtostreamlinethisprocesscanpotentiallyreducetheeffort. 4-9However,\\nourpreviousresearchontheuseofmachinelearning 10indicatedthatwhiletimeefficiencyimproved,\\ntheprecisionoftheresultsfailedtoreachthedesiredlevelofaccuracy,withasensitivityand\\nspecificityof0.24to0.80and0.99to1.00,respectively.Accordingly,amoreprecisemethodfor\\ncitationscreeninginsystematicreviewsrequiresfurtherinvestigation.9-11\\nAlongwiththegrowinginterestinlargelanguagemodels(LLMs),theseadvancedartificial\\nintelligencetoolshaveshowcasedthecapacitytoperformcomplicatedtasks,suchasdataanalysis\\nandtextgenerationusingnaturallanguageprocessingtechniques.12-15Althoughpreviousreports\\nhavesuggestedthefeasibilityofharnessinganLLMforcitationscreeningtasks, 16,17studiesonthe\\ndeploymentofanLLMforextensivecitationscreeninginthedevelopmentofclinicalpractice\\nguidelinesremainlacking.\\nWehypothesizedthatLLM-assistedcitationscreeningcanpotentiallyachievethequalityof\\nmanualcitationscreeningandsignificantlyreducetherequiredmanualworkload.Thus,inthis\\nprospectivestudy,weaimedtocriticallyevaluatetheaccuracyandoperationalefficiencyof\\nLLM-assistedcitationscreeningcomparedwiththoseofconventionalscreeningmethodsusing\\nclinicalquestions(CQs)fromtheJapaneseClinicalPracticeGuidelinesfortheManagementofSepsis\\nandSepticShock(J-SSCG).\\nMethods\\nStudy Design\\nWeconductedaprospectivediagnosticstudytoevaluatetheaccuracyofcitationscreeningusingLLMs.\\nToensuretransparencyandreproducibility,wesubmittedourresearchprotocoltothemedRxivpre-\\nprintserverandtheUniversityHospitalMedicalInformationNetwork(UMIN)ClinicalTrialsRegistry\\nundertheidentifierUMIN000053091onDecember31,2023. 18Wedidnotseekinstitutionalreview\\nboardapprovalbecausethestudydidnotmeetthedefinitionofhumanparticipantresearch.We\\nfollowedtheStandardsforReportingofDiagnosticAccuracy(STARD)guidelines.\\nSetting\\nWeevaluatedtheaccuracyandefficiencyoftheLLM-assistedcitationscreeningmethodusingdata\\nfromthetitleandabstractscreeningprocessfor5CQsintheJ-SSCG2024.TheCQsaredescribedin\\neTable1inSupplement1.DetailsoftheJ-SSCG2024developmentprocesshavebeendescribedina\\npreviousreport,10 andtheconventionalprocessdescribedlaterwascompletedwhenthisstudywas\\nbeingconducted(eAppendixin Supplement1).\\nConventional Citation Screening\\nThroughtheconventionalcitationscreeningprocess,literaturewasselectedby2independent\\nreviewerswhowereclinicalexperts.Thedetailsoftheconventionalcitationscreeningaredescribed\\nintheeAppendixinSupplement1.\\nLLM Screening\\nWeusedGPT-4Turbo(OpenAI),releasedonNovember7,2023,asanLLMtoevaluatetheaccuracy\\nandefficiencyofcitationscreeninginthedevelopmentofclinicalpracticeguidelines.Todevelopthe\\nLLM-assistedcitationscreening,weformulatedaqueryfortheLLMaccordingtotheguidelinesof\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 2/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='promptengineering.19,20WealsoestablishedacommandtoenabletheLLMtoautonomously\\nperformcitationscreeningusingpandas(version1.0.5)inPython(version3.9.0)viatheapplication\\nprogramminginterface.EachcommandincludedarequesttotheLLMtoautomaticallyimplementa\\ncitationscreeningtaskaccordingtotheinclusionandexclusioncriteriabasedontheexactwording\\nofthepatient,population,problem;intervention;comparison;andstudydesign(PICO)sheetineach\\nCQdescribedbytheJ-SSCG2024committeeinconventionalcitationscreeningprocesses(eTable1\\nandeFigure1inSupplement1).Afterimportingthe5setsofliteratureusedinconventionalcitation\\nscreening,theLLM,withoutpriorknowledge,decidedtoincludeorexcludeeachcitationbasedon\\ntheinclusionandexclusioncriteriaintermsofthePICOsheetoftheselectedCQ.Toassessthe\\nworkload,werecordedtheprocessingtimerequiredtocompletethetaskusingPython.The\\nLLM-assistedscreeningprocesswasperformedfromJanuary7to15,2024,inEnglish.Thecodefor\\nthisprocessisavailableonline.21\\nStatistical Analysis\\nWeevaluatedtheaccuracyoftheLLM-assistedcitationscreeningbycalculatingthesensitivityand\\nspecificitywitha95%CI.Intheprimaryanalysis,weusedresultsofthefull-textscreeningsession\\nwiththeconventionalmethodasthereferencestandardbecausethesepublicationswereincludedin\\nthequalitativeevaluation.Inthesecondaryanalysis,resultsofthetitleandabstractscreening\\nsessionusingtheconventionalmethodwereusedasthereferencestandards.Inadditiontothe\\nprimaryandsecondaryanalysis,usingmeta-analysistechniques,wealsocalculatedthepooled\\nsensitivityandspecificityasoverallvaluesfortheresultsinprimary,secondary,andposthocanalyses\\ndescribedlater,inaccordancewiththeCochraneHandbook.22 Weappliedarandom-effectsmodel\\ntoaccountforbothwithin-studyandbetween-studyvariance. 23 Weevaluatedheterogeneityofthe\\nCQsusingtheχ 2 testwithinconsistencyvalues( I2).\\nDurationofthecitationscreeningprocessforeachCQwascomparedforthe2methods.A\\nsummaryofcontinuousvariablesispresentedaseithermeanwithSDormedianwithIQR,as\\nappropriate.Basedonthenormalityofthedistribution,theunpairedt testwasusedforstatistical\\nanalysis.Themetapackageforthemeta-analysisinRversion4.1.2(RFoundationforStatistical\\nComputing)wasused,andallotherstatisticalanalyseswereperformedusingthePrismversion9\\nsoftware(GraphPadSoftware).\\nAsaposthocanalysis,wereviewedtheLLMresultsincasesoffalse-positiveand/orfalse-negative\\nresultstoexplorewhytheLLMincorrectlyjudgedtheresult.Weusedthisreviewasabasistomodify\\ntheprompttooptimizetheaccuracyoftheLLMandexaminehowpromptmodificationaffectedthe\\nLLM’sperformanceoncitationscreeningtasks.Wealsoconductedanotherposthocanalysisinvolving\\n3iterationsofLLMqueryingandadoptedamajority-votingstrategytoaddressthevariabilityanden-\\nhancetherobustnessofLLM-assistedscreening.24Inthisanalysis,weincludedstudiesthatwere\\ndeemedrelevanttoanyofthe3LLM-assistedscreenings.Furthermore,weincorporatedthechain-of\\n-thoughtstrategyintothemodifiedprompt.25Additionally,toassesstheoutcomesofLLM-based\\nmethodsontheresultsofthemeta-analysesfollowedbythecitationscreening,weincorporatedapost\\nhocmeta-analysisthatutilizedstudiesselectedthroughLLM-basedmethods,comparingtheseresults\\nwiththoseobtainedusingconventionalmethods,whereavailable.Theseposthocanalyseswerecon-\\nductedfromJanuary17to19,2024,andfromApril13to19,2024.\\nResults\\nConventional Citation Screening\\nDuringtheconventionalcitationscreeningprocess,112of5634publicationsinCQ1(2.0%),17of\\n3418inCQ2(0.5%),14of1038inCQ3(1.3%),70of4326inCQ4(1.6%),and39of2253inCQ5\\n(1.7%)wereselectedinthetitleandabstractscreeningsession.Atotalof41publications,including8\\nforCQ1,4forCQ2,4forCQ3,17forCQ4,and8forCQ5,wereselectedforqualitativeanalysisin\\nthefull-textscreeningsessionwithineachsystematicreview(Figure 1).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 3/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 3}, page_content='Figure 1. Schematic Diagram of Systematic Review Using Large Language Model (LLM)–Assisted Citation Screening and the Conventional Method\\nRecords identified via databases and registers\\n6831 4312 1146 5464 2417\\nRecords removed before screening\\nDuplicate records\\nremoved 1197 894 108 1138 164\\nTitle and abstract screening\\n5634 3418 1038 4326 2253\\nConventional citation screening LLM-assisted citation screeningTime measurement\\nRecords excluded\\n5522 3401 1024 4256 2214\\nReports not retrieved\\n0002 1 2\\nFull-text screening\\n(standard reference in secondary analysis) Index results by\\nLLM-assisted citation screening\\n112 17 14 68 17\\nRecords excluded\\nTotal\\nDifferent language\\nDifferent publication type\\nDifferent population\\nDifferent study design\\nDuplicate  reports\\n104\\n3\\n61\\n23\\n11\\n6\\n13\\n1\\n0\\n0\\n12\\n0\\n10\\n1\\n6\\n1\\n2\\n0\\n51\\n0\\n21\\n2\\n25\\n3\\n9\\n0\\n9\\n0\\n0\\n0\\nCalculate sensitivity and specificity\\nQualitative analysis\\n(standard reference in primary analysis)\\n8 4 41 78\\nCalculate sensitivity and specificity\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nFlowchartofthesystematicreviewthroughidentification,titleandabstractscreening,andfull-textscreening.Timingofthestatisticsonthea ccuracyandmeasurementofthe\\nscreeningtimebetweenLLM-assistedscreeningandconventionalmethodintheprimaryandsecondaryanalysesarealsodepicted.CQindicatesclinic alquestion.\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 4/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='Primary Analysis of the Accuracy of LLM-Assisted Citation Screening\\nInLLM-assistedcitationscreening,8publicationsforCQ1,1forCQ2,2forCQ3,14forCQ4,and8for\\nCQ5wereincludedinthequalitativeanalysis(eTable2in Supplement1).Intheprimaryanalysis,the\\nsensitivityandspecificityoftheindexresultsofLLM-assistedscreeningwere1.00(95%CI,\\n0.50-1.00)and0.99(95%CI,0.99-0.99)forCQ1,0.25(95%CI,0.03-0.76)and0.99(95%CI,0.99-\\n1.00)forCQ2,0.50(95%CI,0.12-0.88)and0.99(95%CI,0.99-1.00)forCQ3,0.82(95%CI,0.57-\\n0.94)and0.99(95%CI,0.99-1.00)forCQ4,and1.00(95%CI,0.50-1.00)and0.98(95%CI,\\n0.98-0.99)forCQ5,respectively(Figure 2).Thenumbersoftrue-positive,true-negative,false-\\npositive,andfalse-negativeresultsarelistedineTable2in Supplement1.Meta-analysisshowedthat\\ntheintegratedsensitivityandspecificityvaluesamongthe5CQswere0.75(95%CI,0.43-0.92)and\\n0.99(95%CI,0.99-0.99),respectively(Figure2).\\nSecondary Analysis of the Accuracy of LLM-Assisted Citation Screening\\nInthesecondaryanalysis,theintegratedsensitivityandspecificityvaluesacrossthe5CQswere0.49\\n(95%CI,0.35-0.63)and1.00(95%CI,0.99-1.00),respectively(Figure 3;eAppendixin\\nSupplement1).Thenumbersoftrue-positive,true-negative,false-positive,andfalse-negativeresults\\narelistedineTable2in Supplement1.\\nComparison of Overall Citation Screening Time for 100 Studies Between\\nthe LLM-Assisted and Conventional Methods\\nTheLLM-assistedscreeningmethodresultedinsignificantlyshorteroverallprocessingtimefor100\\nstudies(1.30[95%CI,1.28-1.32]minutes)comparedwiththeconventionalscreeningmethod(17.2\\nFigure 2. Accuracy of Large Language Model–Assisted Citation Screening in the Primary Analysis\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n0.25 (0.03-0.76)\\n0.50 (0.12-0.88)\\n0.82 (0.57-0.94)\\n1.00 (0.50-1.00)\\n0.75 (0.43-0.92)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 51%; P = .09 \\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.99-0.99)\\n0.99 (0.99-1.00)\\n0.99 (0.99-1.00)\\n0.99 (0.99-1.00)\\n0.98 (0.98-0.99)\\n0.99 (0.99-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 83%; P < .001\\nSpecificityB\\nTheprimaryanalysisusedresultsoftheincludedpublicationsforqualitativeanalysis,\\nusingtheconventionalmethodasthestandardreference.Theindividualsensitivityand\\nspecificityresultsforeachclinicalquestion(CQ)andintegratedsensitivitiesand\\nspecificitiesacrossCQ1to5areshown,withconfidenceintervalsandinconsistency\\nvalues(I2).\\nFigure 3. Accuracy of Large Language Model–Assisted Citation Screening in the Secondary Analysis\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.34 (0.26-0.43)\\n0.53 (0.30-0.74)\\n0.36 (0.16-0.62)\\n0.53 (0.41-0.64)\\n0.69 (0.53-0.82)\\n0.49 (0.35-0.63)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 76%; P = .002\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (1.00-1.00)\\n1.00 (1.00-1.00)\\n1.00 (0.99-1.00)\\n0.99 (0.98-0.99)\\n0.99 (0.99-0.99)\\n1.00 (0.99-1.00)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 92%; P < .001\\nSpecificityB\\nSecondaryanalysisusedresultsoftheincludedpublicationsforthefull-textscreeningsessionusingtheconventionalmethodasthestandardrefe rence.Theindividualsensitivities\\nandspecificitiesforeachclinicalquestion(CQ)andintegratedsensitivitiesacrossCQ1to5areshown,withconfidenceintervalsandinconsisten cyvalues( I2).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 5/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='[95%CI,14.2–18.6]minutes)(unpaired t test:meandifference,−15.25minutes;95%CI,−17.70to\\n−12.79minutes; P < .001)(eAppendix,eTable3,andeFigure2in Supplement1).\\nPost Hoc Analysis Using the Modified Prompt\\nIntheposthocanalysisusingthemodifiedcommand(eAppendix,eTable4,andeFigure3in\\nSupplement1),theintegratedsensitivityandspecificityvaluesamongthe5CQswere0.89(95%CI,\\n0.74-0.95)and0.98(95%CI,0.97-0.99),respectively( Figure 4).Thenumbersoftrue-positive,\\ntrue-negative,false-positive,andfalse-negativeresultsarelistedineTable5Ain Supplement1.\\nPost Hoc Analysis Using Majority-Vote and Chain-of-Thought Strategies\\nWiththeoriginalpromptandamajority-votestrategy,theintegratedsensitivityandspecificityvalues\\namongthe5CQswere0.75(95%CI,0.43-0.92)and0.99(95%CI,0.98-0.99)intheprimary\\nanalysis(eFigure5andeTable5BinSupplement1).Usingthemodifiedpromptandamajorityvote,\\ntheaggregatesensitivityandspecificityvaluesamongthe5CQswere0.91(95%CI,0.77-0.97)and\\n0.98(95%CI,0.96-0.99)intheprimaryanalysis(Figure 5;eTable5Cin Supplement1).\\nWiththeoriginalpromptandthechain-of-thoughtstrategy(eFigure8in Supplement1),theinte-\\ngratedsensitivityandspecificityvaluesamongthe5CQswere0.71(95%CI,0.45-0.88)and0.99(95%\\nCI,0.98-0.99)intheprimaryanalysis(eFigure9andeTable5DinSupplement1).Usingthemodified\\npromptandthechain-of-thoughtstrategy,theaggregatesensitivityandspecificityvaluesamongthe5\\nCQswere0.87(95%CI,0.67-0.96)and0.98(95%CI,0.96-0.99)intheprimaryanalysis(eFigure11\\nFigure 4. Post Hoc Analysis for the Primary Analysis Using the Modified Prompt\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n1.00 (0.33-0.99)\\n0.75 (0.24-0.97)\\n0.88 (0.63-0.97)\\n1.00 (0.50-1.00)\\n0.89 (0.74-0.95)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 0%; P = .87\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.98-0.99)\\n0.98 (0.98-0.99)\\n0.99 (0.98-1.00)\\n0.96 (0.96-0.97)\\n0.97 (0.96-0.98)\\n0.98 (0.97-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 94%; P < .001\\nSpecificityB\\nPosthocprimaryanalysisadoptedamodifiedpromptbasedonfalse-negativestudies.\\nTheresultsoftheincludedpublicationsforqualitativeanalysisusingconventional\\nmethodswereusedasthestandardreference.Theindividualsensitivitiesand\\nspecificitiesforeachclinicalquestion(CQ)andtheintegratedsensitivitiesacrossCQ1to\\n5areshownwithconfidenceintervalsandinconsistencyvalues( I2).\\nFigure 5. Post Hoc Analysis for the Primary Analysis Using a Majority-Vote Strategy and the Modified Prompt\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n1.00 (0.33-0.99)\\n0.75 (0.24-0.97)\\n0.94 (0.68-0.99)\\n1.00 (0.50-1.00)\\n0.91 (0.77-0.97)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 0%; P = .82\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.98 (0.98-0.99)\\n0.97 (0.97-0.98)\\n0.99 (0.98-0.99)\\n0.95 (0.94-0.95)\\n0.97 (0.96-0.98)\\n0.98 (0.96-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 97%; P < .001\\nSpecificityB\\nPosthocprimaryanalysisadoptedamajority-votestrategyusingamodifiedprompt\\nbasedonfalse-negativestudies.Theresultsoftheincludedpublicationsforqualitative\\nanalysisusingconventionalmethodswereusedasthestandardreference.Theindividual\\nsensitivitiesandspecificitiesforeachclinicalquestion(CQ)andtheintegrated\\nsensitivitiesacrossCQ1to5areshownwithconfidenceintervalsandinconsistency\\nvalues(I2).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 6/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='andeTable5Ein Supplement1).Theresultsofposthocanalysisforthesecondaryanalysisareshownin\\neTable5,eFigure4,eFigure6,eFigure7,eFigure10,andeFigure12in Supplement1.\\nAssociation of LLM-Assisted Citation Screening With Results of the Meta-Analysis\\nTheresultsofthemeta-analysiswerecomparablebetweenthe2screeningmethods.Thisfinding\\nindicatesthatstudiesclassifiedasfalsenegativesdidnotsubstantiallyaltertheoverallconclusionsof\\nthemeta-analysisregardingCQ4(eAppendixandeFigure13-16inSupplement1).\\nDiscussion\\nInthisstudy,wefoundthatthesensitivityandspecificityoftheLLM-assistedcitationscreeningwere\\n0.25to1.00and0.98to0.99,respectively,withstudiesincludedbyconventionalcitationscreening\\nduringthefull-textscreeningsessionasthereferencestandard.Moreover,theposthocanalysis\\nusingamodifiedcommandpromptexhibitedhighersensitivity(0.75-1.00)whilemaintainingthe\\nspecificity(0.96-0.99).Furthermore,theprocessingtimeoftheLLM-assistedcitationscreening\\nmethodwassignificantlyshorterthanthatoftheconventionalmethod.Fewstudieshave\\ninvestigatedtheefficiencyandworkloadreductionofLLM-assistedcitationscreeninginthe\\nsystematicreviewprocessforthedevelopmentofclinicalpracticeguidelines,andtheresultsofthis\\nstudymayleadtotheappropriateutilizationofthebestevidence.\\nOurfindingsindicatedthepotentialofLLM-assistedcitationscreening,whichhassubstantial\\nadvantagesoverpreviouslyreportedsemiautomatedscreeningtools.First,theLLM-assistedcitation\\nscreeningmayleadtoimprovedefficiencyandworkloadreductionduringthescreeningprocess\\nbecausealthoughsemiautomatedcitationscreeningtoolsusingmachinelearningshowedenhanced\\nefficiencyandworkloadreduction,theirapplicationrequirestrainingdataforthecitationscreening\\nprocess,inputtingpredefinedkeyarticles,andsomeprocessesofhumanreviewers.4,9,26Incontrast,\\nLLM-assistedcitationscreeningdoesnotrequireanyfurthertrainingdataoreffortsofhuman\\nreviewersinthescreeningprocess.OurstudyfurtherfoundthatLLM-assistedcitationscreening\\nhelpedsavetimeinthesystematicreviewprocess,withamorethan10-foldreductioninthetime\\nrequiredtocompletetheprocess.Althoughthisfindingisconsistentwithotherreportsshowingthe\\nadvantageofcitationscreeningusingsemiautomatedscreeningsoftware,9,10,26eliminatingthe\\nnecessityofinputtingkeystudieswouldsaveadditionaltimeusingLLM-assistedcitationscreening.\\nSecond,LLM-assistedcitationmayhaveahigheraccuracythanthesemiautomatedtool.\\nPreviousstudiesonsemiautomatedcitationscreeningtoolsreportedsensitivityrangingfrom0.75to\\n0.90,9,26,27whichiscomparablewiththeaccuracyofourstudy;h owever,ourpre viousresearchon\\nthistool10 showedavariablesensitivityof0.24to0.80forthesamedatasetusedinthepresent\\nstudy.Moreover,wefoundahighersensitivityof0.53to0.95withlowervariabilityinthesecondary\\nanalysis,suggestingthepotentialadvantageofLLM-assistedcitationscreeningfordiscriminating\\ntherelevantliterature.Althoughwefoundhighspecificityinprimaryandsecondaryanalyses,\\ncautioniswarrantedregardingthepotentialoverestimationofthemodel’sperformanceowingtothe\\nhighproportionoftruenegatives.\\nThird,LLM-assistedcitationscreeninghasotherpotentialadvantages,includinghigher\\ngeneralizabilityacrossvarioustopicsandformats,auser-friendlyinterfacetosimplifyuser\\ninteraction,continuousdevelopmentofthemodeltoimprovetheaccuracyovertimeforeachtask\\nperformed,andfunctionalextensibilitytoexpanditsapplicability.Theseadvantagessupporttheuse\\nofLLMsforcitationscreeningbyreducingtheworkloadandmaintainingsufficientaccuracy,leading\\ntoatransformationofthesystematicreviewprocess.\\nInourposthocanalysis,themodifiedpromptimprovedsensitivitywithslightlydecreased\\nspecificity,suggestingthatpromptcontentmaysubstantiallyaffectthequalityofsystematicreviews\\nusingtheLLM.Recentresearchonpromptengineeringhasrevealedhowpromptdesigninfluences\\noutput,highlightingtacticsforenhancingefficiency.19,20Intheinitialprompt,wedescribedprompt\\nsetsaccordingtothelistofPICOoftheselectedclinicalquestions.Subsequentanalysisbasedonthe\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 7/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='predeterminedstudyprotocolrevealedacautiouslylowsensitivityforCQ2(sensitivity:0.25;\\nspecificity:0.99).AfterreviewingtheLLMresponsestotheinadvertentlyexcludedstudies(eTable4\\ninSupplement1),wefoundthattheLLMstrictlyappliedthecriteriaaccordingtotheprompt.Inthe\\ntitleandabstractscreeningsession,humanreviewerstendedtobemoreconservativeintheir\\nselectionofliteraturetoensurethatrelevantliteraturewasnotexcluded.Consideringthisnatureof\\nthetitleandabstractscreeningsession,suchsubtlenuancesinthepromptcommandsmayhave\\nbeennecessary.Accordingly,wemodifiedthepromptcommandtoloosenthecriteriaandmaximize\\nsensitivity.Uponevaluatingtheposthocanalysisresults,theLLM-assistedcitationscreening\\nimprovedinaccuracy.Throughthismodificationprocess,wediscoveredanoptimaldescriptionof\\nthecitationscreeningcommandprompts.Whilefalsepositivesmaybesomewhattolerableunder\\ncertaincircumstances,falsenegativesaremorecritical,astheysignifymissedopportunitiesto\\nincluderelevantstudies,potentiallyunderminingthethoroughnessofthesystematicreview.\\nConsequently,itisimperativetorecalibratethethresholdsettingstoprioritizesensitivity,thereby\\nminimizingtheoccurrenceoffalsenegatives.\\nToenhancetheaccuracyofLLM-assistedcitationscreening,weimplementedamajority-vote\\nstrategyandachain-of-thoughtstrategy. 24,25TheLLMcangeneratedifferentrecommendations\\nacrossmultipleruns,leadingtoperformanceuncertaintyowingtotheprobabilisticresponsesofthe\\nLLMs.ToensuretheimpactofuncertainresponsesfromtheLLMonthecitationscreening\\nperformance,weexaminedtheoutcomesofthemajority-votestrategy.Themajority-votestrategy\\nenhancedthesensitivityofthescreeningsessionsusingtheoriginalandmodifiedprompts,witha\\nslightdecreaseinspecificity.Thissuggeststhatthisstrategymaybepromisingforimprovingthe\\naccuracyandreliabilityofcitationscreening.Inaddition,thechain-of-thoughtstrategieshavebeen\\nrecognizedasapromptengineeringtechniqueelicitingaccurateresponsesfromLLMs.25 However,\\nourposthocanalysesdidnotdemonstratetheeffectivenessofthisstrategyinenhancingprecision.\\nAlthoughourinvestigationwaslimitedtothechain-of-thoughtstrategy’seffects,futureresearch\\nshouldelucidatetheinfluenceofadditionalpromptengineeringtechniques,suchastheregeneration\\nofsuperiorpromptsbyLLMsandtheimplementationofaself-correctionstrategy,onthe\\nperformanceofLLM-assistedcitationscreening.\\nLimitations\\nThisstudyhasseverallimitations.First,becauseourstudyfocusedexclusivelyonasinglemedical\\nsettingandaliteraturereviewforclinicalguidelinedevelopment,theapplicabilityofourfindingsto\\notherfieldsisuncertain.FuturestudiesshouldtesttheLLM-assistedmodelacrossvarious\\nopportunitiesforsystematicreviewtovalidateitsutilityandperformanceforawiderrangeoftasks.\\nSecond,thequalityoftheLLMoutputsdependsonregularmodelupdates,whichmayvaryin\\nfrequencyandimpact,therebyaffectingthestandardizationofreviewqualityovertime.Third,the\\nreferencestandardusedinthisstudywasselectedbyalimitednumberofmembersoftheJ-SSCG\\n2024workinggroup,whoareexpertsinthefield;however,we cannotruleoutthepossibilitythat\\nessentialliteraturewasnotselected,whichmayhaveledtomisclassificationofthereference\\nstandard.Fourth,althoughtheLLMcouldnotaccesstheresultsofconventionalscreening,the\\nauthorsinthisstudywerenotmaskedtothestandardreference.Therefore,weregisteredthestudy\\nprotocolbeforetheanalysistoensuretransparencyoftheperformanceevaluation.Furthermore,\\nwebelievethatintegratedsensitivityestimatesbasedonprimaryandsecondaryanalysesare\\ninsufficienttosupporttheimplementationofthisapproachinpracticalsettingsbecausethisstudy\\nremainsintheproof-of-conceptstage.However,we believethatthisstudyprovidesreasonable\\nevidencejustifyingfurtherresearchandvalidationforpracticaldeployment.Despitethese\\nlimitations,theintegrationofadvancedartificialintelligence,suchasanLLM,intosystematicreviews\\nholdsgreatpromise,heraldingafuturewithenhancedspeedandbreadthofknowledgesynthesis.\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 8/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content=\"Conclusions\\nThisprospectivediagnosticstudyfoundthatLLM-assistedcitationscreeningachievedreasonably\\nhighspecificity,acceptablesensitivity,andreducedprocessingtime.Theuseofthisinnovative\\napproachshouldbefurthervalidatedtoenhancetheefficiencyandaccessibilityofsystematicreview\\nprocedures.\\nARTICLE INFORMATION\\nAccepted for Publication:May6,2024.\\nPublished: July8,2024.doi: 10.1001/jamanetworkopen.2024.20496\\nOpen Access:Thisisanopenaccessarticledistributedunderthetermsofthe CC-BYLicense.©2024OamiT\\netal. JAMA Network Open.\\nCorresponding Author:TakehikoOami,MD,PhD,DepartmentofEmergencyandCriticalCareMedicine,\\nChibaUniversityGraduateSchoolofMedicine,1-8-1Inohana,Chuo,Chiba260-8677,Japan\\n(seveneleven711thanks39@msn.com).\\nAuthor Affiliations:DepartmentofEmergencyandCriticalCareMedicine,ChibaUniversityGraduateSchoolof\\nMedicine,Chiba,Japan(Oami,Nakada);DepartmentofPreventiveServices,KyotoUniversityGraduateSchoolof\\nMedicine,Kyoto,Japan(Okada);HealthServicesandSystemsResearch,Duke-NUSMedicalSchool,National\\nUniversityofSingapore,Singapore(Okada).\\nAuthor Contributions:DrOamihadfullaccesstoallofthedatainthestudyandtakesresponsibilityforthe\\nintegrityofthedataandtheaccuracyofthedataanalysis.\\nConcept and design:Allauthors.\\nAcquisition, analysis, or interpretation of data:Allauthors.\\nDrafting of the manuscript:Oami.\\nCritical review of the manuscript for important intellectual content:Allauthors.\\nStatistical analysis:Oami.\\nAdministrative, technical, or material support:Nakada.\\nSupervision: Okada,Nakada.\\nConflict of Interest Disclosures:DrOkadareportedreceivingaresearchgrantfromtheZOLLFoundationand\\noverseasscholarshipsfromtheFukudaFoundationforMedicalTechnologyandInternationalMedicalResearch\\nFoundation.DrNakadareportedbeingthechiefoperatingofficerofSmart119Incoutsidethesubmittedwork.No\\notherdisclosureswerereported.\\nData Sharing Statement:SeeSupplement2.\\nAdditional Contributions:WewouldliketothankallcontributorstotheJapaneseSocietyofIntensiveCare\\nMedicineandtheJapaneseAssociationofEmergencyMedicine.Wealsothankthefollowingcontributorsfor\\nprovidingthedataofconventionalcitationscreening:TakehitoSato,MD,PhD(NagoyaUniversityHospital);\\nHiroshiMatsuura,MD,PhD(OsakaPrefecturalNakakawachiEmergencyandCriticalCareCenter);MayuHikone,\\nMD,MSc(TokyoMetropolitanBokutohHospital);KoheiYamada,MD,MPH(NationalDefenseMedicalCollege\\nHospital);TetsuyaYumoto,MD,PhD(OkayamaUniversity);KenichiTetsuhara,MD,PhD(FukuokaChildren's\\nHospital);HirokiNagasawa,MD,PhD(JuntendoUniversity);HiroshiYonekura,MD,PhD(FujitaHealthUniversity\\nBantaneHospital);JunFujinaga,MD,MPH(KurashikiCentralHospital);RyoHisamune,MD(OsakaMedicaland\\nPharmaceuticalUniversity);ShigeruKoba,MD(NerimaHikarigaokaHospital);SuguruNonami,MD(KyotoKatsura\\nHospital);TakefumiTsunemitsu,MD(HyogoPrefecturalAmagasakiGeneralMedicalCenter);YasutakaHamai,MD\\n(KyotoUniversity);YukiWakabayashi,MSN,RN(KobeCityCenterGeneralHospital);AkitoMizuno,MD(Izinkai\\nTakedaGeneralHospital);YuAmemiya,MD(OsakaMedicalandPharmaceuticalUniversity);TeppeiMurata,MD,\\nPhD(MiyazakiPrefecturalNobeokaHospital);AkiraEndo,MD,PhD(TsuchiuraKyodoGeneralHospital);Ryohei\\nYamamoto,MD,PhD(FukushimaMedicalUniversity);MasahiroKashiura,MD(JichiMedicalUniversitySaitama\\nMedicalCenter);MasaakiSakuraya,MD(JAHiroshimaGeneralHospital);TatsumaFukuda,MD,PhD(Toranomon\\nHospital).Theseindividualswerenotcompensatedfortheirtime.DrOkadathankstheJapanSocietyforthe\\nPromotionofScienceOverseasResearchFellowships,ZOLLFoundation,overseasscholarshipsfromtheFukuda\\nFoundationforMedicalTechnology,andInternationalMedicalResearchFoundation.WethankHonyakuCenterInc\\nforEnglishlanguageediting.\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 9/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024\"),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='REFERENCES\\n1. BorahR,BrownAW,CapersPL,KaiserKA.Analysisofthetimeandworkersneededtoconductsystematic\\nreviewsofmedicalinterventionsusingdatafromthePROSPEROregistry. BMJ Open.2017;7(2):e012545.doi: 10.\\n1136/bmjopen-2016-012545\\n2. SampsonM,TetzlaffJ,UrquhartC.Precisionofhealthcaresystematicreviewsearchesinacross-sectional\\nsample.Res Synth Methods.2011;2(2):119-125.doi: 10.1002/jrsm.42\\n3. WangZ,NayfehT,TetzlaffJ,O’BlenisP,MuradMH.Errorratesofhumanreviewersduringabstractscreeningin\\nsystematicreviews. PLoS One.2020;15(1):e0227742.doi: 10.1371/journal.pone.0227742\\n4. vandeSchootR,deBruinJ,SchramR,etal.Anopensourcemachinelearningframeworkforefficientand\\ntransparentsystematicreviews. Nat Mach Intell.2021;3:125-133.doi: 10.1038/s42256-020-00287-7\\n5. MarshallIJ,WallaceBC.Towardsystematicreviewautomation:apracticalguidetousingmachinelearningtools\\ninresearchsynthesis. Syst Rev.2019;8(1):163.doi: 10.1186/s13643-019-1074-9\\n6. HarrisonH,GriffinSJ,KuhnI,Usher-SmithJA.Softwaretoolstosupporttitleandabstractscreeningfor\\nsystematicreviewsinhealthcare:anevaluation. BMC Med Res Methodol.2020;20(1):7.doi: 10.1186/s12874-020-\\n0897-3\\n7. O’Mara-EvesA,ThomasJ,McNaughtJ,MiwaM,AnaniadouS.Usingtextminingforstudyidentificationin\\nsystematicreviews:asystematicreviewofcurrentapproaches. Syst Rev.2015;4(1):5.doi: 10.1186/2046-4053-4-5\\n8. WallaceBC,TrikalinosTA,LauJ,BrodleyC,SchmidCH.Semi-automatedscreeningofbiomedicalcitationsfor\\nsystematicreviews. BMC Bioinformatics.2010;11:55.doi: 10.1186/1471-2105-11-55\\n9. GatesA,GuitardS,PillayJ,etal.Performanceandusabilityofmachinelearningforscreeninginsystematic\\nreviews:acomparativeevaluationofthreetools. Syst Rev.2019;8(1):278.doi: 10.1186/s13643-019-1222-2\\n10. OamiT,OkadaY,SakurayaM,FukudaT,ShimeN,NakadaTA.Efficiencyandworkloadreductionofsemi-\\nautomatedcitationscreeningsoftwareforcreatingclinicalpracticeguidelines:aprospectiveobservationalstudy.\\nJ Epidemiol.PublishedonlineDecember16,2023.doi: 10.2188/jea.JE20230227\\n11. O’ConnorAM,TsafnatG,ThomasJ,GlasziouP,GilbertSB,HuttonB.Aquestionoftrust:canwebuildan\\nevidencebasetogaintrustinsystematicreviewautomationtechnologies? Syst Rev.2019;8(1):143.doi: 10.1186/\\ns13643-019-1062-0\\n12. HaugCJ,DrazenJM.Artificialintelligenceandmachinelearninginclinicalmedicine,2023. N Engl J Med.2023;\\n388(13):1201-1208.doi:10.1056/NEJMra2302038\\n13. LeeP,BubeckS,PetroJ.Benefits,limits,andrisksofGPT-4asanAIchatbotformedicine. N Engl J Med.2023;\\n388(13):1233-1239.doi:10.1056/NEJMsr2214184\\n14. SinghalK,AziziS,TuT,etal.Largelanguagemodelsencodeclinicalknowledge. Nature.2023;620(7972):\\n172-180.doi:10.1038/s41586-023-06291-2\\n15. ShahNH,EntwistleD,PfefferMA.Creationandadoptionoflargelanguagemodelsinmedicine. JAMA.2023;\\n330(9):866-869.doi:10.1001/jama.2023.14217\\n16. KohandelGargariO,MahmoudiMH,HajisafaraliM,SamieeR.Enhancingtitleandabstractscreeningfor\\nsystematicreviewswithGPT-3.5turbo. BMJ Evid Based Med.2024;29(1):69-70.\\n17. QureshiR,ShaughnessyD,GillKAR,RobinsonKA,LiT,AgaiE.AreChatGPTandlargelanguagemodels“the\\nanswer”tobringingusclosertosystematicreviewautomation? Syst Rev.2023;12(1):72.doi: 10.1186/s13643-023-\\n02243-z\\n18. OamiT,OkadaY,NakadaTa.Citationscreeningusinglargelanguagemodelsforcreatingclinicalpractice\\nguidelines:aprotocolforaprospectivestudy. medRxiv.PreprintpostedonlineDecember31,2023.doi: 10.1101/2023.\\n12.29.23300652\\n19. GirayL.PromptengineeringwithChatGPT:aguideforacademicwriters. Ann Biomed Eng.2023;51(12):\\n2629-2633.doi:10.1007/s10439-023-03272-4\\n20. MeskóB.Promptengineeringasanimportantemergingskillformedicalprofessionals:tutorial. J Med Internet\\nRes.2023;25:e50638.doi: 10.2196/50638\\n21. GPT-assistedcitationscreening.GitHub.AccessedJune3,2024. https://github.com/seveneleven711thanks39/\\ngpt-assisted_citation_screening\\n22. HigginsJPT,ThomasJ,ChandlerJ,CumpstonM,LiT,PageMJ,eds. Cochrane Handbook for Systematic Reviews\\nof Interventions version 6.0 (updated July 2019).Cochrane;2019.doi: 10.1002/9781119536604\\n23. DerSimonianR,LairdN.Meta-analysisinclinicaltrials. Control Clin Trials.1986;7(3):177-188.doi: 10.1016/0197-\\n2456(86)90046-2\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 10/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 10}, page_content='24. AbdullahiT,SinghR,EickhoffC.LearningtomakerareandcomplexdiagnoseswithgenerativeAIassistance:\\nqualitativestudyofpopularlargelanguagemodels. JMIR Med Educ.2024;10:e51391.doi:10.2196/51391\\n25. WangX,WeiJ,SchuurmansD,LeQ,ChiEH-h,ZhouD.Self-consistencyimproveschainofthoughtreasoning\\ninlanguagemodels. arXiv.PreprintupdatedMarch7,2023.doi: 10.48550/arXiv.2203.11171\\n26. Perlman-ArrowS,LooN,BobrovitzN,YanT,AroraRK.Areal-worldevaluationoftheimplementationofNLP\\ntechnology in abstract screening of a systematic review.Res Synth Methods. 2023;14(4):608-621. doi:10.1002/\\njrsm.1636\\n27. GatesA,JohnsonC,HartlingL.Technology-assistedtitleandabstractscreeningforsystematicreviews:\\naretrospectiveevaluationoftheAbstrackrmachinelearningtool. Syst Rev.2018;7(1):45.doi: 10.1186/s13643-018-\\n0707-8\\nSUPPLEMENT 1.\\neAppendix.\\neTable 1.ListofthePatient/Population/Problem,Intervention,andComparisonoftheSelectedClinicalQuestions\\neTable 2.StatisticsontheAccuracyofLargeLanguageModel–AssistedCitationScreening\\neTable 3.ComparisonofCitationScreeningTimefor100StudiesperPersonBetweentheLargeLanguageModel–\\nAssistedandConventionalMethods\\neTable 4.ListofUnidentifiedStudiesUsingtheLargeLanguageModel–AssistedCitationScreeningforQualitative\\nAnalysis\\neTable 5.PostHocAnalysisforEvaluatingtheAccuracyofLargeLanguageModel–AssistedCitationScreening\\neFigure 1.CommandPromptfortheLLMCitationScreeningTask\\neFigure 2.ComparisonofCitationScreeningTimefor100StudiesBetweentheLargeLanguageModel–Assisted\\nandConventionalMethods\\neFigure 3.ModifiedCommandPromptfortheLLMCitationScreeningTaskinthePostHocAnalysis\\neFigure 4.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPrompt\\neFigure 5.PostHocAnalysisforthePrimaryAnalysisUsingtheOriginalPromptandaMajority-VoteStrategy\\neFigure 6.PostHocAnalysisfortheSecondaryAnalysisUsingtheOriginalPromptandaMajority-VoteStrategy\\neFigure 7.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPromptandaMajorityVote-Strategy\\neFigure 8.ModifiedCommandPromptIntegratingtheChain-of-ThoughtStrategyfortheLLMCitationScreening\\nTaskinthePostHocAnalysis\\neFigure 9.PostHocAnalysisforthePrimaryAnalysisUsingtheOriginalPromptandtheChain-of-ThoughtStrategy\\neFigure 10.PostHocAnalysisfortheSecondaryAnalysisUsingtheOriginalPromptandtheChain-Of-Thought\\nStrategy\\neFigure 11.PostHocAnalysisforthePrimaryAnalysisUsingtheModifiedPromptandtheChain-of-Thought\\nStrategy\\neFigure 12.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPromptandtheChain-of-Thought\\nStrategy\\neFigure 13.ForestPlotsofPairwiseMeta-AnalysesforShort-TermMortality\\neFigure 14.ForestPlotsofPairwiseMeta-AnalysesforICUMortality\\neFigure 15.ForestPlotsofPairwiseMeta-AnalysesforICULengthOfStay\\neFigure 16.ForestPlotsofPairwiseMeta-AnalysesforVentilator-FreeDays\\neReferences.\\nSUPPLEMENT 2.\\nData Sharing Statement\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 11/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/LLM.pdf', 'page': 0}, page_content='Original Investigation| Statistics and Research Methods\\nPerformance of a Large Language Model in Screening Citations\\nTakehikoOami,MD,PhD;YoheiOkada,MD,PhD;Taka-akiNakada,MD,PhD\\nAbstract\\nIMPORTANCE Largelanguagemodels(LLMs)arepromisingastoolsforcitationscreeningin\\nsystematicreviews.H owever,theirapplicabilityhasnotyetbeendetermined.\\nOBJECTIVE ToevaluatetheaccuracyandefficiencyofanLLMintitleandabstractliterature\\nscreening.\\nDESIGN, SETTING, AND PARTICIPANTSThisprospectivediagnosticstudyusedthedatafromthe\\ntitleandabstractscreeningprocessfor5clinicalquestions(CQs)inthedevelopmentoftheJapanese\\nClinicalPracticeGuidelinesforManagementofSepsisandSepticShock.TheLLMdecidedtoinclude\\norexcludecitationsbasedontheinclusionandexclusioncriteriaintermsofpatient,population,\\nproblem;intervention;comparison;andstudydesignoftheselectedCQandwascomparedwiththe\\nconventionalmethodfortitleandabstractscreening.ThisstudywasconductedfromJanuary7to\\n15,2024.'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 0}, page_content='15,2024.\\nEXPOSURES LLM(GPT-4Turbo)–assistedcitationscreeningortheconventionalmethod.\\nMAIN OUTCOMES AND MEASURESThesensitivityandspecificityoftheLLM-assistedscreening\\nprocesswascalculated,andthefull-textscreeningresultusingtheconventionalmethodwassetas\\nthereferencestandardintheprimaryanalysis.Pooledsensitivityandspecificitywerealsoestimated,\\nandscreeningtimesofthe2methodswerecompared.\\nRESULTS Intheconventionalcitationscreeningprocess,8of5634publicationsinCQ1,4of3418in\\nCQ2,4of1038inCQ3,17of4326inCQ4,and8of2253inCQ5wereselected.Intheprimary\\nanalysisof5CQs,LLM-assistedcitationscreeningdemonstratedanintegratedsensitivityof0.75\\n(95%CI,0.43to0.92)andspecificityof0.99(95%CI,0.99to0.99).Posthocmodificationstothe\\ncommandpromptimprovedtheintegratedsensitivityto0.91(95%CI,0.77to0.97)without\\nsubstantiallycompromisingspecificity(0.98[95%CI,0.96to0.99]).Additionally,LLM-assisted\\nscreeningwasassociatedwithreducedtimeforprocessing100studies(1.3minutesvs17.2minutes'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 0}, page_content='forconventionalscreeningmethods;meandifference,−15.25minutes[95%CI,−17.70to−12.79\\nminutes]).\\nCONCLUSIONS AND RELEVANCEInthisprospectivediagnosticstudyinvestigatingthe\\nperformanceofLLM-assistedcitationscreening,themodeldemonstratedacceptablesensitivityand\\nreasonablyhighspecificitywithreducedprocessingtime.Thisnovelmethodcouldpotentially\\nenhanceefficiencyandreduceworkloadinsystematicreviews.\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496\\nKey Points\\nQuestion Howaccurateandefficientis\\nalargelanguagemodel(LLM)for\\nscreeningtitlesandabstractsforarticle\\ninclusioninasystematicreview?\\nFindings Inthisdiagnosticstudy,\\nLLM-assistedcitationscreening\\nexhibitedacceptablesensitivityand\\nreasonablyhighspecificityinevaluating\\n5clinicalquestions,withposthoc\\npromptmodificationsfurtherimproving\\naccuracy.Thescreeningtimefor100\\nstudieswassignificantlyreduced\\ncomparedwiththatof\\nconventionalmethods.\\nMeaning Thesefindingssuggestthat\\nLLM-assistedcitationscreeningcould'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 0}, page_content='LLM-assistedcitationscreeningcould\\nofferareliableandtime-efficient\\nalternativetosystematicreview\\nprocesses.\\n+ Supplemental content\\nAuthoraffiliationsandarticleinformationare\\nlistedattheendofthisarticle.\\nOpen Access.ThisisanopenaccessarticledistributedunderthetermsoftheCC-BYLicense.\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 1/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 1}, page_content='Introduction\\nClinicalpracticeguidelinesaresystematicallydevelopedbasedonasynthesisofthecurrentbest\\nevidenceandprovidecliniciansandpatientswithessentialguidanceforclinicaldecision-making.\\nDuringguidelinedevelopment,collectingandcompilingthelatestresearchfindingsinsystematic\\nreviewsisacriticalprocessrequiringextensiveworkandeffortforscreeningtherelevantliterature,\\ntherebypresentingamajorchallengeinthedevelopmentofsuchguidelines.1-3Recentprogressin\\napplyingmachinelearningtostreamlinethisprocesscanpotentiallyreducetheeffort. 4-9However,\\nourpreviousresearchontheuseofmachinelearning 10indicatedthatwhiletimeefficiencyimproved,\\ntheprecisionoftheresultsfailedtoreachthedesiredlevelofaccuracy,withasensitivityand\\nspecificityof0.24to0.80and0.99to1.00,respectively.Accordingly,amoreprecisemethodfor\\ncitationscreeninginsystematicreviewsrequiresfurtherinvestigation.9-11\\nAlongwiththegrowinginterestinlargelanguagemodels(LLMs),theseadvancedartificial'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 1}, page_content='intelligencetoolshaveshowcasedthecapacitytoperformcomplicatedtasks,suchasdataanalysis\\nandtextgenerationusingnaturallanguageprocessingtechniques.12-15Althoughpreviousreports\\nhavesuggestedthefeasibilityofharnessinganLLMforcitationscreeningtasks, 16,17studiesonthe\\ndeploymentofanLLMforextensivecitationscreeninginthedevelopmentofclinicalpractice\\nguidelinesremainlacking.\\nWehypothesizedthatLLM-assistedcitationscreeningcanpotentiallyachievethequalityof\\nmanualcitationscreeningandsignificantlyreducetherequiredmanualworkload.Thus,inthis\\nprospectivestudy,weaimedtocriticallyevaluatetheaccuracyandoperationalefficiencyof\\nLLM-assistedcitationscreeningcomparedwiththoseofconventionalscreeningmethodsusing\\nclinicalquestions(CQs)fromtheJapaneseClinicalPracticeGuidelinesfortheManagementofSepsis\\nandSepticShock(J-SSCG).\\nMethods\\nStudy Design\\nWeconductedaprospectivediagnosticstudytoevaluatetheaccuracyofcitationscreeningusingLLMs.'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 1}, page_content='Toensuretransparencyandreproducibility,wesubmittedourresearchprotocoltothemedRxivpre-\\nprintserverandtheUniversityHospitalMedicalInformationNetwork(UMIN)ClinicalTrialsRegistry\\nundertheidentifierUMIN000053091onDecember31,2023. 18Wedidnotseekinstitutionalreview\\nboardapprovalbecausethestudydidnotmeetthedefinitionofhumanparticipantresearch.We\\nfollowedtheStandardsforReportingofDiagnosticAccuracy(STARD)guidelines.\\nSetting\\nWeevaluatedtheaccuracyandefficiencyoftheLLM-assistedcitationscreeningmethodusingdata\\nfromthetitleandabstractscreeningprocessfor5CQsintheJ-SSCG2024.TheCQsaredescribedin\\neTable1inSupplement1.DetailsoftheJ-SSCG2024developmentprocesshavebeendescribedina\\npreviousreport,10 andtheconventionalprocessdescribedlaterwascompletedwhenthisstudywas\\nbeingconducted(eAppendixin Supplement1).\\nConventional Citation Screening\\nThroughtheconventionalcitationscreeningprocess,literaturewasselectedby2independent\\nreviewerswhowereclinicalexperts.Thedetailsoftheconventionalcitationscreeningaredescribed'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 1}, page_content='intheeAppendixinSupplement1.\\nLLM Screening\\nWeusedGPT-4Turbo(OpenAI),releasedonNovember7,2023,asanLLMtoevaluatetheaccuracy\\nandefficiencyofcitationscreeninginthedevelopmentofclinicalpracticeguidelines.Todevelopthe\\nLLM-assistedcitationscreening,weformulatedaqueryfortheLLMaccordingtotheguidelinesof\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 2/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='promptengineering.19,20WealsoestablishedacommandtoenabletheLLMtoautonomously\\nperformcitationscreeningusingpandas(version1.0.5)inPython(version3.9.0)viatheapplication\\nprogramminginterface.EachcommandincludedarequesttotheLLMtoautomaticallyimplementa\\ncitationscreeningtaskaccordingtotheinclusionandexclusioncriteriabasedontheexactwording\\nofthepatient,population,problem;intervention;comparison;andstudydesign(PICO)sheetineach\\nCQdescribedbytheJ-SSCG2024committeeinconventionalcitationscreeningprocesses(eTable1\\nandeFigure1inSupplement1).Afterimportingthe5setsofliteratureusedinconventionalcitation\\nscreening,theLLM,withoutpriorknowledge,decidedtoincludeorexcludeeachcitationbasedon\\ntheinclusionandexclusioncriteriaintermsofthePICOsheetoftheselectedCQ.Toassessthe\\nworkload,werecordedtheprocessingtimerequiredtocompletethetaskusingPython.The\\nLLM-assistedscreeningprocesswasperformedfromJanuary7to15,2024,inEnglish.Thecodefor\\nthisprocessisavailableonline.21\\nStatistical Analysis'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='Statistical Analysis\\nWeevaluatedtheaccuracyoftheLLM-assistedcitationscreeningbycalculatingthesensitivityand\\nspecificitywitha95%CI.Intheprimaryanalysis,weusedresultsofthefull-textscreeningsession\\nwiththeconventionalmethodasthereferencestandardbecausethesepublicationswereincludedin\\nthequalitativeevaluation.Inthesecondaryanalysis,resultsofthetitleandabstractscreening\\nsessionusingtheconventionalmethodwereusedasthereferencestandards.Inadditiontothe\\nprimaryandsecondaryanalysis,usingmeta-analysistechniques,wealsocalculatedthepooled\\nsensitivityandspecificityasoverallvaluesfortheresultsinprimary,secondary,andposthocanalyses\\ndescribedlater,inaccordancewiththeCochraneHandbook.22 Weappliedarandom-effectsmodel\\ntoaccountforbothwithin-studyandbetween-studyvariance. 23 Weevaluatedheterogeneityofthe\\nCQsusingtheχ 2 testwithinconsistencyvalues( I2).\\nDurationofthecitationscreeningprocessforeachCQwascomparedforthe2methods.A\\nsummaryofcontinuousvariablesispresentedaseithermeanwithSDormedianwithIQR,as'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='appropriate.Basedonthenormalityofthedistribution,theunpairedt testwasusedforstatistical\\nanalysis.Themetapackageforthemeta-analysisinRversion4.1.2(RFoundationforStatistical\\nComputing)wasused,andallotherstatisticalanalyseswereperformedusingthePrismversion9\\nsoftware(GraphPadSoftware).\\nAsaposthocanalysis,wereviewedtheLLMresultsincasesoffalse-positiveand/orfalse-negative\\nresultstoexplorewhytheLLMincorrectlyjudgedtheresult.Weusedthisreviewasabasistomodify\\ntheprompttooptimizetheaccuracyoftheLLMandexaminehowpromptmodificationaffectedthe\\nLLM’sperformanceoncitationscreeningtasks.Wealsoconductedanotherposthocanalysisinvolving\\n3iterationsofLLMqueryingandadoptedamajority-votingstrategytoaddressthevariabilityanden-\\nhancetherobustnessofLLM-assistedscreening.24Inthisanalysis,weincludedstudiesthatwere\\ndeemedrelevanttoanyofthe3LLM-assistedscreenings.Furthermore,weincorporatedthechain-of\\n-thoughtstrategyintothemodifiedprompt.25Additionally,toassesstheoutcomesofLLM-based'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='methodsontheresultsofthemeta-analysesfollowedbythecitationscreening,weincorporatedapost\\nhocmeta-analysisthatutilizedstudiesselectedthroughLLM-basedmethods,comparingtheseresults\\nwiththoseobtainedusingconventionalmethods,whereavailable.Theseposthocanalyseswerecon-\\nductedfromJanuary17to19,2024,andfromApril13to19,2024.\\nResults\\nConventional Citation Screening\\nDuringtheconventionalcitationscreeningprocess,112of5634publicationsinCQ1(2.0%),17of\\n3418inCQ2(0.5%),14of1038inCQ3(1.3%),70of4326inCQ4(1.6%),and39of2253inCQ5\\n(1.7%)wereselectedinthetitleandabstractscreeningsession.Atotalof41publications,including8\\nforCQ1,4forCQ2,4forCQ3,17forCQ4,and8forCQ5,wereselectedforqualitativeanalysisin\\nthefull-textscreeningsessionwithineachsystematicreview(Figure 1).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 3/11'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 2}, page_content='Downloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 3}, page_content='Figure 1. Schematic Diagram of Systematic Review Using Large Language Model (LLM)–Assisted Citation Screening and the Conventional Method\\nRecords identified via databases and registers\\n6831 4312 1146 5464 2417\\nRecords removed before screening\\nDuplicate records\\nremoved 1197 894 108 1138 164\\nTitle and abstract screening\\n5634 3418 1038 4326 2253\\nConventional citation screening LLM-assisted citation screeningTime measurement\\nRecords excluded\\n5522 3401 1024 4256 2214\\nReports not retrieved\\n0002 1 2\\nFull-text screening\\n(standard reference in secondary analysis) Index results by\\nLLM-assisted citation screening\\n112 17 14 68 17\\nRecords excluded\\nTotal\\nDifferent language\\nDifferent publication type\\nDifferent population\\nDifferent study design\\nDuplicate  reports\\n104\\n3\\n61\\n23\\n11\\n6\\n13\\n1\\n0\\n0\\n12\\n0\\n10\\n1\\n6\\n1\\n2\\n0\\n51\\n0\\n21\\n2\\n25\\n3\\n9\\n0\\n9\\n0\\n0\\n0\\nCalculate sensitivity and specificity\\nQualitative analysis\\n(standard reference in primary analysis)\\n8 4 41 78\\nCalculate sensitivity and specificity'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 3}, page_content='8 4 41 78\\nCalculate sensitivity and specificity\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nCQ 1 CQ 2 CQ 3 CQ 4 CQ 5\\nFlowchartofthesystematicreviewthroughidentification,titleandabstractscreening,andfull-textscreening.Timingofthestatisticsonthea ccuracyandmeasurementofthe\\nscreeningtimebetweenLLM-assistedscreeningandconventionalmethodintheprimaryandsecondaryanalysesarealsodepicted.CQindicatesclinic alquestion.\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 4/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='Primary Analysis of the Accuracy of LLM-Assisted Citation Screening\\nInLLM-assistedcitationscreening,8publicationsforCQ1,1forCQ2,2forCQ3,14forCQ4,and8for\\nCQ5wereincludedinthequalitativeanalysis(eTable2in Supplement1).Intheprimaryanalysis,the\\nsensitivityandspecificityoftheindexresultsofLLM-assistedscreeningwere1.00(95%CI,\\n0.50-1.00)and0.99(95%CI,0.99-0.99)forCQ1,0.25(95%CI,0.03-0.76)and0.99(95%CI,0.99-\\n1.00)forCQ2,0.50(95%CI,0.12-0.88)and0.99(95%CI,0.99-1.00)forCQ3,0.82(95%CI,0.57-\\n0.94)and0.99(95%CI,0.99-1.00)forCQ4,and1.00(95%CI,0.50-1.00)and0.98(95%CI,\\n0.98-0.99)forCQ5,respectively(Figure 2).Thenumbersoftrue-positive,true-negative,false-\\npositive,andfalse-negativeresultsarelistedineTable2in Supplement1.Meta-analysisshowedthat\\ntheintegratedsensitivityandspecificityvaluesamongthe5CQswere0.75(95%CI,0.43-0.92)and\\n0.99(95%CI,0.99-0.99),respectively(Figure2).\\nSecondary Analysis of the Accuracy of LLM-Assisted Citation Screening'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='Inthesecondaryanalysis,theintegratedsensitivityandspecificityvaluesacrossthe5CQswere0.49\\n(95%CI,0.35-0.63)and1.00(95%CI,0.99-1.00),respectively(Figure 3;eAppendixin\\nSupplement1).Thenumbersoftrue-positive,true-negative,false-positive,andfalse-negativeresults\\narelistedineTable2in Supplement1.\\nComparison of Overall Citation Screening Time for 100 Studies Between\\nthe LLM-Assisted and Conventional Methods\\nTheLLM-assistedscreeningmethodresultedinsignificantlyshorteroverallprocessingtimefor100\\nstudies(1.30[95%CI,1.28-1.32]minutes)comparedwiththeconventionalscreeningmethod(17.2\\nFigure 2. Accuracy of Large Language Model–Assisted Citation Screening in the Primary Analysis\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n0.25 (0.03-0.76)\\n0.50 (0.12-0.88)\\n0.82 (0.57-0.94)\\n1.00 (0.50-1.00)\\n0.75 (0.43-0.92)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 51%; P = .09 \\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.99-0.99)'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='CQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.99-0.99)\\n0.99 (0.99-1.00)\\n0.99 (0.99-1.00)\\n0.99 (0.99-1.00)\\n0.98 (0.98-0.99)\\n0.99 (0.99-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 83%; P < .001\\nSpecificityB\\nTheprimaryanalysisusedresultsoftheincludedpublicationsforqualitativeanalysis,\\nusingtheconventionalmethodasthestandardreference.Theindividualsensitivityand\\nspecificityresultsforeachclinicalquestion(CQ)andintegratedsensitivitiesand\\nspecificitiesacrossCQ1to5areshown,withconfidenceintervalsandinconsistency\\nvalues(I2).\\nFigure 3. Accuracy of Large Language Model–Assisted Citation Screening in the Secondary Analysis\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.34 (0.26-0.43)\\n0.53 (0.30-0.74)\\n0.36 (0.16-0.62)\\n0.53 (0.41-0.64)\\n0.69 (0.53-0.82)\\n0.49 (0.35-0.63)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 76%; P = .002\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (1.00-1.00)\\n1.00 (1.00-1.00)\\n1.00 (0.99-1.00)\\n0.99 (0.98-0.99)'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='1.00 (0.99-1.00)\\n0.99 (0.98-0.99)\\n0.99 (0.99-0.99)\\n1.00 (0.99-1.00)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 92%; P < .001\\nSpecificityB\\nSecondaryanalysisusedresultsoftheincludedpublicationsforthefull-textscreeningsessionusingtheconventionalmethodasthestandardrefe rence.Theindividualsensitivities\\nandspecificitiesforeachclinicalquestion(CQ)andintegratedsensitivitiesacrossCQ1to5areshown,withconfidenceintervalsandinconsisten cyvalues( I2).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 5/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='[95%CI,14.2–18.6]minutes)(unpaired t test:meandifference,−15.25minutes;95%CI,−17.70to\\n−12.79minutes; P < .001)(eAppendix,eTable3,andeFigure2in Supplement1).\\nPost Hoc Analysis Using the Modified Prompt\\nIntheposthocanalysisusingthemodifiedcommand(eAppendix,eTable4,andeFigure3in\\nSupplement1),theintegratedsensitivityandspecificityvaluesamongthe5CQswere0.89(95%CI,\\n0.74-0.95)and0.98(95%CI,0.97-0.99),respectively( Figure 4).Thenumbersoftrue-positive,\\ntrue-negative,false-positive,andfalse-negativeresultsarelistedineTable5Ain Supplement1.\\nPost Hoc Analysis Using Majority-Vote and Chain-of-Thought Strategies\\nWiththeoriginalpromptandamajority-votestrategy,theintegratedsensitivityandspecificityvalues\\namongthe5CQswere0.75(95%CI,0.43-0.92)and0.99(95%CI,0.98-0.99)intheprimary\\nanalysis(eFigure5andeTable5BinSupplement1).Usingthemodifiedpromptandamajorityvote,\\ntheaggregatesensitivityandspecificityvaluesamongthe5CQswere0.91(95%CI,0.77-0.97)and'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='0.98(95%CI,0.96-0.99)intheprimaryanalysis(Figure 5;eTable5Cin Supplement1).\\nWiththeoriginalpromptandthechain-of-thoughtstrategy(eFigure8in Supplement1),theinte-\\ngratedsensitivityandspecificityvaluesamongthe5CQswere0.71(95%CI,0.45-0.88)and0.99(95%\\nCI,0.98-0.99)intheprimaryanalysis(eFigure9andeTable5DinSupplement1).Usingthemodified\\npromptandthechain-of-thoughtstrategy,theaggregatesensitivityandspecificityvaluesamongthe5\\nCQswere0.87(95%CI,0.67-0.96)and0.98(95%CI,0.96-0.99)intheprimaryanalysis(eFigure11\\nFigure 4. Post Hoc Analysis for the Primary Analysis Using the Modified Prompt\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n1.00 (0.33-0.99)\\n0.75 (0.24-0.97)\\n0.88 (0.63-0.97)\\n1.00 (0.50-1.00)\\n0.89 (0.74-0.95)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 0%; P = .87\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.98-0.99)\\n0.98 (0.98-0.99)\\n0.99 (0.98-1.00)\\n0.96 (0.96-0.97)\\n0.97 (0.96-0.98)\\n0.98 (0.97-0.99)\\nSpecificity'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='0.97 (0.96-0.98)\\n0.98 (0.97-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 94%; P < .001\\nSpecificityB\\nPosthocprimaryanalysisadoptedamodifiedpromptbasedonfalse-negativestudies.\\nTheresultsoftheincludedpublicationsforqualitativeanalysisusingconventional\\nmethodswereusedasthestandardreference.Theindividualsensitivitiesand\\nspecificitiesforeachclinicalquestion(CQ)andtheintegratedsensitivitiesacrossCQ1to\\n5areshownwithconfidenceintervalsandinconsistencyvalues( I2).\\nFigure 5. Post Hoc Analysis for the Primary Analysis Using a Majority-Vote Strategy and the Modified Prompt\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n1.00 (0.33-0.99)\\n0.75 (0.24-0.97)\\n0.94 (0.68-0.99)\\n1.00 (0.50-1.00)\\n0.91 (0.77-0.97)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 0%; P = .82\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.98 (0.98-0.99)\\n0.97 (0.97-0.98)\\n0.99 (0.98-0.99)\\n0.95 (0.94-0.95)\\n0.97 (0.96-0.98)\\n0.98 (0.96-0.99)'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='0.97 (0.96-0.98)\\n0.98 (0.96-0.99)\\nSpecificity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 97%; P < .001\\nSpecificityB\\nPosthocprimaryanalysisadoptedamajority-votestrategyusingamodifiedprompt\\nbasedonfalse-negativestudies.Theresultsoftheincludedpublicationsforqualitative\\nanalysisusingconventionalmethodswereusedasthestandardreference.Theindividual\\nsensitivitiesandspecificitiesforeachclinicalquestion(CQ)andtheintegrated\\nsensitivitiesacrossCQ1to5areshownwithconfidenceintervalsandinconsistency\\nvalues(I2).\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 6/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='andeTable5Ein Supplement1).Theresultsofposthocanalysisforthesecondaryanalysisareshownin\\neTable5,eFigure4,eFigure6,eFigure7,eFigure10,andeFigure12in Supplement1.\\nAssociation of LLM-Assisted Citation Screening With Results of the Meta-Analysis\\nTheresultsofthemeta-analysiswerecomparablebetweenthe2screeningmethods.Thisfinding\\nindicatesthatstudiesclassifiedasfalsenegativesdidnotsubstantiallyaltertheoverallconclusionsof\\nthemeta-analysisregardingCQ4(eAppendixandeFigure13-16inSupplement1).\\nDiscussion\\nInthisstudy,wefoundthatthesensitivityandspecificityoftheLLM-assistedcitationscreeningwere\\n0.25to1.00and0.98to0.99,respectively,withstudiesincludedbyconventionalcitationscreening\\nduringthefull-textscreeningsessionasthereferencestandard.Moreover,theposthocanalysis\\nusingamodifiedcommandpromptexhibitedhighersensitivity(0.75-1.00)whilemaintainingthe\\nspecificity(0.96-0.99).Furthermore,theprocessingtimeoftheLLM-assistedcitationscreening'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='methodwassignificantlyshorterthanthatoftheconventionalmethod.Fewstudieshave\\ninvestigatedtheefficiencyandworkloadreductionofLLM-assistedcitationscreeninginthe\\nsystematicreviewprocessforthedevelopmentofclinicalpracticeguidelines,andtheresultsofthis\\nstudymayleadtotheappropriateutilizationofthebestevidence.\\nOurfindingsindicatedthepotentialofLLM-assistedcitationscreening,whichhassubstantial\\nadvantagesoverpreviouslyreportedsemiautomatedscreeningtools.First,theLLM-assistedcitation\\nscreeningmayleadtoimprovedefficiencyandworkloadreductionduringthescreeningprocess\\nbecausealthoughsemiautomatedcitationscreeningtoolsusingmachinelearningshowedenhanced\\nefficiencyandworkloadreduction,theirapplicationrequirestrainingdataforthecitationscreening\\nprocess,inputtingpredefinedkeyarticles,andsomeprocessesofhumanreviewers.4,9,26Incontrast,\\nLLM-assistedcitationscreeningdoesnotrequireanyfurthertrainingdataoreffortsofhuman\\nreviewersinthescreeningprocess.OurstudyfurtherfoundthatLLM-assistedcitationscreening'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='helpedsavetimeinthesystematicreviewprocess,withamorethan10-foldreductioninthetime\\nrequiredtocompletetheprocess.Althoughthisfindingisconsistentwithotherreportsshowingthe\\nadvantageofcitationscreeningusingsemiautomatedscreeningsoftware,9,10,26eliminatingthe\\nnecessityofinputtingkeystudieswouldsaveadditionaltimeusingLLM-assistedcitationscreening.\\nSecond,LLM-assistedcitationmayhaveahigheraccuracythanthesemiautomatedtool.\\nPreviousstudiesonsemiautomatedcitationscreeningtoolsreportedsensitivityrangingfrom0.75to\\n0.90,9,26,27whichiscomparablewiththeaccuracyofourstudy;h owever,ourpre viousresearchon\\nthistool10 showedavariablesensitivityof0.24to0.80forthesamedatasetusedinthepresent\\nstudy.Moreover,wefoundahighersensitivityof0.53to0.95withlowervariabilityinthesecondary\\nanalysis,suggestingthepotentialadvantageofLLM-assistedcitationscreeningfordiscriminating\\ntherelevantliterature.Althoughwefoundhighspecificityinprimaryandsecondaryanalyses,'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='cautioniswarrantedregardingthepotentialoverestimationofthemodel’sperformanceowingtothe\\nhighproportionoftruenegatives.\\nThird,LLM-assistedcitationscreeninghasotherpotentialadvantages,includinghigher\\ngeneralizabilityacrossvarioustopicsandformats,auser-friendlyinterfacetosimplifyuser\\ninteraction,continuousdevelopmentofthemodeltoimprovetheaccuracyovertimeforeachtask\\nperformed,andfunctionalextensibilitytoexpanditsapplicability.Theseadvantagessupporttheuse\\nofLLMsforcitationscreeningbyreducingtheworkloadandmaintainingsufficientaccuracy,leading\\ntoatransformationofthesystematicreviewprocess.\\nInourposthocanalysis,themodifiedpromptimprovedsensitivitywithslightlydecreased\\nspecificity,suggestingthatpromptcontentmaysubstantiallyaffectthequalityofsystematicreviews\\nusingtheLLM.Recentresearchonpromptengineeringhasrevealedhowpromptdesigninfluences\\noutput,highlightingtacticsforenhancingefficiency.19,20Intheinitialprompt,wedescribedprompt'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 6}, page_content='setsaccordingtothelistofPICOoftheselectedclinicalquestions.Subsequentanalysisbasedonthe\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 7/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='predeterminedstudyprotocolrevealedacautiouslylowsensitivityforCQ2(sensitivity:0.25;\\nspecificity:0.99).AfterreviewingtheLLMresponsestotheinadvertentlyexcludedstudies(eTable4\\ninSupplement1),wefoundthattheLLMstrictlyappliedthecriteriaaccordingtotheprompt.Inthe\\ntitleandabstractscreeningsession,humanreviewerstendedtobemoreconservativeintheir\\nselectionofliteraturetoensurethatrelevantliteraturewasnotexcluded.Consideringthisnatureof\\nthetitleandabstractscreeningsession,suchsubtlenuancesinthepromptcommandsmayhave\\nbeennecessary.Accordingly,wemodifiedthepromptcommandtoloosenthecriteriaandmaximize\\nsensitivity.Uponevaluatingtheposthocanalysisresults,theLLM-assistedcitationscreening\\nimprovedinaccuracy.Throughthismodificationprocess,wediscoveredanoptimaldescriptionof\\nthecitationscreeningcommandprompts.Whilefalsepositivesmaybesomewhattolerableunder\\ncertaincircumstances,falsenegativesaremorecritical,astheysignifymissedopportunitiesto'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='includerelevantstudies,potentiallyunderminingthethoroughnessofthesystematicreview.\\nConsequently,itisimperativetorecalibratethethresholdsettingstoprioritizesensitivity,thereby\\nminimizingtheoccurrenceoffalsenegatives.\\nToenhancetheaccuracyofLLM-assistedcitationscreening,weimplementedamajority-vote\\nstrategyandachain-of-thoughtstrategy. 24,25TheLLMcangeneratedifferentrecommendations\\nacrossmultipleruns,leadingtoperformanceuncertaintyowingtotheprobabilisticresponsesofthe\\nLLMs.ToensuretheimpactofuncertainresponsesfromtheLLMonthecitationscreening\\nperformance,weexaminedtheoutcomesofthemajority-votestrategy.Themajority-votestrategy\\nenhancedthesensitivityofthescreeningsessionsusingtheoriginalandmodifiedprompts,witha\\nslightdecreaseinspecificity.Thissuggeststhatthisstrategymaybepromisingforimprovingthe\\naccuracyandreliabilityofcitationscreening.Inaddition,thechain-of-thoughtstrategieshavebeen\\nrecognizedasapromptengineeringtechniqueelicitingaccurateresponsesfromLLMs.25 However,'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='ourposthocanalysesdidnotdemonstratetheeffectivenessofthisstrategyinenhancingprecision.\\nAlthoughourinvestigationwaslimitedtothechain-of-thoughtstrategy’seffects,futureresearch\\nshouldelucidatetheinfluenceofadditionalpromptengineeringtechniques,suchastheregeneration\\nofsuperiorpromptsbyLLMsandtheimplementationofaself-correctionstrategy,onthe\\nperformanceofLLM-assistedcitationscreening.\\nLimitations\\nThisstudyhasseverallimitations.First,becauseourstudyfocusedexclusivelyonasinglemedical\\nsettingandaliteraturereviewforclinicalguidelinedevelopment,theapplicabilityofourfindingsto\\notherfieldsisuncertain.FuturestudiesshouldtesttheLLM-assistedmodelacrossvarious\\nopportunitiesforsystematicreviewtovalidateitsutilityandperformanceforawiderrangeoftasks.\\nSecond,thequalityoftheLLMoutputsdependsonregularmodelupdates,whichmayvaryin\\nfrequencyandimpact,therebyaffectingthestandardizationofreviewqualityovertime.Third,the\\nreferencestandardusedinthisstudywasselectedbyalimitednumberofmembersoftheJ-SSCG'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='2024workinggroup,whoareexpertsinthefield;however,we cannotruleoutthepossibilitythat\\nessentialliteraturewasnotselected,whichmayhaveledtomisclassificationofthereference\\nstandard.Fourth,althoughtheLLMcouldnotaccesstheresultsofconventionalscreening,the\\nauthorsinthisstudywerenotmaskedtothestandardreference.Therefore,weregisteredthestudy\\nprotocolbeforetheanalysistoensuretransparencyoftheperformanceevaluation.Furthermore,\\nwebelievethatintegratedsensitivityestimatesbasedonprimaryandsecondaryanalysesare\\ninsufficienttosupporttheimplementationofthisapproachinpracticalsettingsbecausethisstudy\\nremainsintheproof-of-conceptstage.However,we believethatthisstudyprovidesreasonable\\nevidencejustifyingfurtherresearchandvalidationforpracticaldeployment.Despitethese\\nlimitations,theintegrationofadvancedartificialintelligence,suchasanLLM,intosystematicreviews\\nholdsgreatpromise,heraldingafuturewithenhancedspeedandbreadthofknowledgesynthesis.'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 7}, page_content='JAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 8/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content='Conclusions\\nThisprospectivediagnosticstudyfoundthatLLM-assistedcitationscreeningachievedreasonably\\nhighspecificity,acceptablesensitivity,andreducedprocessingtime.Theuseofthisinnovative\\napproachshouldbefurthervalidatedtoenhancetheefficiencyandaccessibilityofsystematicreview\\nprocedures.\\nARTICLE INFORMATION\\nAccepted for Publication:May6,2024.\\nPublished: July8,2024.doi: 10.1001/jamanetworkopen.2024.20496\\nOpen Access:Thisisanopenaccessarticledistributedunderthetermsofthe CC-BYLicense.©2024OamiT\\netal. JAMA Network Open.\\nCorresponding Author:TakehikoOami,MD,PhD,DepartmentofEmergencyandCriticalCareMedicine,\\nChibaUniversityGraduateSchoolofMedicine,1-8-1Inohana,Chuo,Chiba260-8677,Japan\\n(seveneleven711thanks39@msn.com).\\nAuthor Affiliations:DepartmentofEmergencyandCriticalCareMedicine,ChibaUniversityGraduateSchoolof\\nMedicine,Chiba,Japan(Oami,Nakada);DepartmentofPreventiveServices,KyotoUniversityGraduateSchoolof'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content='Medicine,Kyoto,Japan(Okada);HealthServicesandSystemsResearch,Duke-NUSMedicalSchool,National\\nUniversityofSingapore,Singapore(Okada).\\nAuthor Contributions:DrOamihadfullaccesstoallofthedatainthestudyandtakesresponsibilityforthe\\nintegrityofthedataandtheaccuracyofthedataanalysis.\\nConcept and design:Allauthors.\\nAcquisition, analysis, or interpretation of data:Allauthors.\\nDrafting of the manuscript:Oami.\\nCritical review of the manuscript for important intellectual content:Allauthors.\\nStatistical analysis:Oami.\\nAdministrative, technical, or material support:Nakada.\\nSupervision: Okada,Nakada.\\nConflict of Interest Disclosures:DrOkadareportedreceivingaresearchgrantfromtheZOLLFoundationand\\noverseasscholarshipsfromtheFukudaFoundationforMedicalTechnologyandInternationalMedicalResearch\\nFoundation.DrNakadareportedbeingthechiefoperatingofficerofSmart119Incoutsidethesubmittedwork.No\\notherdisclosureswerereported.\\nData Sharing Statement:SeeSupplement2.'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content=\"Data Sharing Statement:SeeSupplement2.\\nAdditional Contributions:WewouldliketothankallcontributorstotheJapaneseSocietyofIntensiveCare\\nMedicineandtheJapaneseAssociationofEmergencyMedicine.Wealsothankthefollowingcontributorsfor\\nprovidingthedataofconventionalcitationscreening:TakehitoSato,MD,PhD(NagoyaUniversityHospital);\\nHiroshiMatsuura,MD,PhD(OsakaPrefecturalNakakawachiEmergencyandCriticalCareCenter);MayuHikone,\\nMD,MSc(TokyoMetropolitanBokutohHospital);KoheiYamada,MD,MPH(NationalDefenseMedicalCollege\\nHospital);TetsuyaYumoto,MD,PhD(OkayamaUniversity);KenichiTetsuhara,MD,PhD(FukuokaChildren's\\nHospital);HirokiNagasawa,MD,PhD(JuntendoUniversity);HiroshiYonekura,MD,PhD(FujitaHealthUniversity\\nBantaneHospital);JunFujinaga,MD,MPH(KurashikiCentralHospital);RyoHisamune,MD(OsakaMedicaland\\nPharmaceuticalUniversity);ShigeruKoba,MD(NerimaHikarigaokaHospital);SuguruNonami,MD(KyotoKatsura\\nHospital);TakefumiTsunemitsu,MD(HyogoPrefecturalAmagasakiGeneralMedicalCenter);YasutakaHamai,MD\"),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content='(KyotoUniversity);YukiWakabayashi,MSN,RN(KobeCityCenterGeneralHospital);AkitoMizuno,MD(Izinkai\\nTakedaGeneralHospital);YuAmemiya,MD(OsakaMedicalandPharmaceuticalUniversity);TeppeiMurata,MD,\\nPhD(MiyazakiPrefecturalNobeokaHospital);AkiraEndo,MD,PhD(TsuchiuraKyodoGeneralHospital);Ryohei\\nYamamoto,MD,PhD(FukushimaMedicalUniversity);MasahiroKashiura,MD(JichiMedicalUniversitySaitama\\nMedicalCenter);MasaakiSakuraya,MD(JAHiroshimaGeneralHospital);TatsumaFukuda,MD,PhD(Toranomon\\nHospital).Theseindividualswerenotcompensatedfortheirtime.DrOkadathankstheJapanSocietyforthe\\nPromotionofScienceOverseasResearchFellowships,ZOLLFoundation,overseasscholarshipsfromtheFukuda\\nFoundationforMedicalTechnology,andInternationalMedicalResearchFoundation.WethankHonyakuCenterInc\\nforEnglishlanguageediting.\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 9/11'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 8}, page_content='Downloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='REFERENCES\\n1. BorahR,BrownAW,CapersPL,KaiserKA.Analysisofthetimeandworkersneededtoconductsystematic\\nreviewsofmedicalinterventionsusingdatafromthePROSPEROregistry. BMJ Open.2017;7(2):e012545.doi: 10.\\n1136/bmjopen-2016-012545\\n2. SampsonM,TetzlaffJ,UrquhartC.Precisionofhealthcaresystematicreviewsearchesinacross-sectional\\nsample.Res Synth Methods.2011;2(2):119-125.doi: 10.1002/jrsm.42\\n3. WangZ,NayfehT,TetzlaffJ,O’BlenisP,MuradMH.Errorratesofhumanreviewersduringabstractscreeningin\\nsystematicreviews. PLoS One.2020;15(1):e0227742.doi: 10.1371/journal.pone.0227742\\n4. vandeSchootR,deBruinJ,SchramR,etal.Anopensourcemachinelearningframeworkforefficientand\\ntransparentsystematicreviews. Nat Mach Intell.2021;3:125-133.doi: 10.1038/s42256-020-00287-7\\n5. MarshallIJ,WallaceBC.Towardsystematicreviewautomation:apracticalguidetousingmachinelearningtools\\ninresearchsynthesis. Syst Rev.2019;8(1):163.doi: 10.1186/s13643-019-1074-9'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='6. HarrisonH,GriffinSJ,KuhnI,Usher-SmithJA.Softwaretoolstosupporttitleandabstractscreeningfor\\nsystematicreviewsinhealthcare:anevaluation. BMC Med Res Methodol.2020;20(1):7.doi: 10.1186/s12874-020-\\n0897-3\\n7. O’Mara-EvesA,ThomasJ,McNaughtJ,MiwaM,AnaniadouS.Usingtextminingforstudyidentificationin\\nsystematicreviews:asystematicreviewofcurrentapproaches. Syst Rev.2015;4(1):5.doi: 10.1186/2046-4053-4-5\\n8. WallaceBC,TrikalinosTA,LauJ,BrodleyC,SchmidCH.Semi-automatedscreeningofbiomedicalcitationsfor\\nsystematicreviews. BMC Bioinformatics.2010;11:55.doi: 10.1186/1471-2105-11-55\\n9. GatesA,GuitardS,PillayJ,etal.Performanceandusabilityofmachinelearningforscreeninginsystematic\\nreviews:acomparativeevaluationofthreetools. Syst Rev.2019;8(1):278.doi: 10.1186/s13643-019-1222-2\\n10. OamiT,OkadaY,SakurayaM,FukudaT,ShimeN,NakadaTA.Efficiencyandworkloadreductionofsemi-\\nautomatedcitationscreeningsoftwareforcreatingclinicalpracticeguidelines:aprospectiveobservationalstudy.'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='J Epidemiol.PublishedonlineDecember16,2023.doi: 10.2188/jea.JE20230227\\n11. O’ConnorAM,TsafnatG,ThomasJ,GlasziouP,GilbertSB,HuttonB.Aquestionoftrust:canwebuildan\\nevidencebasetogaintrustinsystematicreviewautomationtechnologies? Syst Rev.2019;8(1):143.doi: 10.1186/\\ns13643-019-1062-0\\n12. HaugCJ,DrazenJM.Artificialintelligenceandmachinelearninginclinicalmedicine,2023. N Engl J Med.2023;\\n388(13):1201-1208.doi:10.1056/NEJMra2302038\\n13. LeeP,BubeckS,PetroJ.Benefits,limits,andrisksofGPT-4asanAIchatbotformedicine. N Engl J Med.2023;\\n388(13):1233-1239.doi:10.1056/NEJMsr2214184\\n14. SinghalK,AziziS,TuT,etal.Largelanguagemodelsencodeclinicalknowledge. Nature.2023;620(7972):\\n172-180.doi:10.1038/s41586-023-06291-2\\n15. ShahNH,EntwistleD,PfefferMA.Creationandadoptionoflargelanguagemodelsinmedicine. JAMA.2023;\\n330(9):866-869.doi:10.1001/jama.2023.14217\\n16. KohandelGargariO,MahmoudiMH,HajisafaraliM,SamieeR.Enhancingtitleandabstractscreeningfor'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='systematicreviewswithGPT-3.5turbo. BMJ Evid Based Med.2024;29(1):69-70.\\n17. QureshiR,ShaughnessyD,GillKAR,RobinsonKA,LiT,AgaiE.AreChatGPTandlargelanguagemodels“the\\nanswer”tobringingusclosertosystematicreviewautomation? Syst Rev.2023;12(1):72.doi: 10.1186/s13643-023-\\n02243-z\\n18. OamiT,OkadaY,NakadaTa.Citationscreeningusinglargelanguagemodelsforcreatingclinicalpractice\\nguidelines:aprotocolforaprospectivestudy. medRxiv.PreprintpostedonlineDecember31,2023.doi: 10.1101/2023.\\n12.29.23300652\\n19. GirayL.PromptengineeringwithChatGPT:aguideforacademicwriters. Ann Biomed Eng.2023;51(12):\\n2629-2633.doi:10.1007/s10439-023-03272-4\\n20. MeskóB.Promptengineeringasanimportantemergingskillformedicalprofessionals:tutorial. J Med Internet\\nRes.2023;25:e50638.doi: 10.2196/50638\\n21. GPT-assistedcitationscreening.GitHub.AccessedJune3,2024. https://github.com/seveneleven711thanks39/\\ngpt-assisted_citation_screening'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 9}, page_content='gpt-assisted_citation_screening\\n22. HigginsJPT,ThomasJ,ChandlerJ,CumpstonM,LiT,PageMJ,eds. Cochrane Handbook for Systematic Reviews\\nof Interventions version 6.0 (updated July 2019).Cochrane;2019.doi: 10.1002/9781119536604\\n23. DerSimonianR,LairdN.Meta-analysisinclinicaltrials. Control Clin Trials.1986;7(3):177-188.doi: 10.1016/0197-\\n2456(86)90046-2\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations\\nJAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 10/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 10}, page_content='24. AbdullahiT,SinghR,EickhoffC.LearningtomakerareandcomplexdiagnoseswithgenerativeAIassistance:\\nqualitativestudyofpopularlargelanguagemodels. JMIR Med Educ.2024;10:e51391.doi:10.2196/51391\\n25. WangX,WeiJ,SchuurmansD,LeQ,ChiEH-h,ZhouD.Self-consistencyimproveschainofthoughtreasoning\\ninlanguagemodels. arXiv.PreprintupdatedMarch7,2023.doi: 10.48550/arXiv.2203.11171\\n26. Perlman-ArrowS,LooN,BobrovitzN,YanT,AroraRK.Areal-worldevaluationoftheimplementationofNLP\\ntechnology in abstract screening of a systematic review.Res Synth Methods. 2023;14(4):608-621. doi:10.1002/\\njrsm.1636\\n27. GatesA,JohnsonC,HartlingL.Technology-assistedtitleandabstractscreeningforsystematicreviews:\\naretrospectiveevaluationoftheAbstrackrmachinelearningtool. Syst Rev.2018;7(1):45.doi: 10.1186/s13643-018-\\n0707-8\\nSUPPLEMENT 1.\\neAppendix.\\neTable 1.ListofthePatient/Population/Problem,Intervention,andComparisonoftheSelectedClinicalQuestions\\neTable 2.StatisticsontheAccuracyofLargeLanguageModel–AssistedCitationScreening'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 10}, page_content='eTable 3.ComparisonofCitationScreeningTimefor100StudiesperPersonBetweentheLargeLanguageModel–\\nAssistedandConventionalMethods\\neTable 4.ListofUnidentifiedStudiesUsingtheLargeLanguageModel–AssistedCitationScreeningforQualitative\\nAnalysis\\neTable 5.PostHocAnalysisforEvaluatingtheAccuracyofLargeLanguageModel–AssistedCitationScreening\\neFigure 1.CommandPromptfortheLLMCitationScreeningTask\\neFigure 2.ComparisonofCitationScreeningTimefor100StudiesBetweentheLargeLanguageModel–Assisted\\nandConventionalMethods\\neFigure 3.ModifiedCommandPromptfortheLLMCitationScreeningTaskinthePostHocAnalysis\\neFigure 4.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPrompt\\neFigure 5.PostHocAnalysisforthePrimaryAnalysisUsingtheOriginalPromptandaMajority-VoteStrategy\\neFigure 6.PostHocAnalysisfortheSecondaryAnalysisUsingtheOriginalPromptandaMajority-VoteStrategy\\neFigure 7.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPromptandaMajorityVote-Strategy'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 10}, page_content='eFigure 8.ModifiedCommandPromptIntegratingtheChain-of-ThoughtStrategyfortheLLMCitationScreening\\nTaskinthePostHocAnalysis\\neFigure 9.PostHocAnalysisforthePrimaryAnalysisUsingtheOriginalPromptandtheChain-of-ThoughtStrategy\\neFigure 10.PostHocAnalysisfortheSecondaryAnalysisUsingtheOriginalPromptandtheChain-Of-Thought\\nStrategy\\neFigure 11.PostHocAnalysisforthePrimaryAnalysisUsingtheModifiedPromptandtheChain-of-Thought\\nStrategy\\neFigure 12.PostHocAnalysisfortheSecondaryAnalysisUsingtheModifiedPromptandtheChain-of-Thought\\nStrategy\\neFigure 13.ForestPlotsofPairwiseMeta-AnalysesforShort-TermMortality\\neFigure 14.ForestPlotsofPairwiseMeta-AnalysesforICUMortality\\neFigure 15.ForestPlotsofPairwiseMeta-AnalysesforICULengthOfStay\\neFigure 16.ForestPlotsofPairwiseMeta-AnalysesforVentilator-FreeDays\\neReferences.\\nSUPPLEMENT 2.\\nData Sharing Statement\\nJAMA Network Open |Statistics and Research Methods PerformanceofaLargeLanguageModelinScreeningCitations'),\n",
       " Document(metadata={'source': '../data/LLM.pdf', 'page': 10}, page_content='JAMA Network Open.2024;7(7):e2420496.doi:10.1001/jamanetworkopen.2024.20496 (Reprinted) July 8,2024 11/11\\nDownloaded from jamanetwork.com by guest on 11/14/2024')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model = 'llama3.2:1b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(chunks, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x19db31651c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(\n",
    "    model = 'llama3.2:1b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the following question using the context data only\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    Questions: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000019DB31651C0>, search_kwargs={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({'input': \"Give summary of the discussion\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Give summary of the discussion',\n",
       " 'context': [Document(metadata={'source': '../data/LLM.pdf', 'page': 3}, page_content='Figure 1. Schematic Diagram of Systematic Review Using Large Language Model (LLM)–Assisted Citation Screening and the Conventional Method\\nRecords identified via databases and registers\\n6831 4312 1146 5464 2417\\nRecords removed before screening\\nDuplicate records\\nremoved 1197 894 108 1138 164\\nTitle and abstract screening\\n5634 3418 1038 4326 2253\\nConventional citation screening LLM-assisted citation screeningTime measurement\\nRecords excluded\\n5522 3401 1024 4256 2214\\nReports not retrieved\\n0002 1 2\\nFull-text screening\\n(standard reference in secondary analysis) Index results by\\nLLM-assisted citation screening\\n112 17 14 68 17\\nRecords excluded\\nTotal\\nDifferent language\\nDifferent publication type\\nDifferent population\\nDifferent study design\\nDuplicate  reports\\n104\\n3\\n61\\n23\\n11\\n6\\n13\\n1\\n0\\n0\\n12\\n0\\n10\\n1\\n6\\n1\\n2\\n0\\n51\\n0\\n21\\n2\\n25\\n3\\n9\\n0\\n9\\n0\\n0\\n0\\nCalculate sensitivity and specificity\\nQualitative analysis\\n(standard reference in primary analysis)\\n8 4 41 78\\nCalculate sensitivity and specificity'),\n",
       "  Document(metadata={'source': '../data/LLM.pdf', 'page': 4}, page_content='Primary Analysis of the Accuracy of LLM-Assisted Citation Screening\\nInLLM-assistedcitationscreening,8publicationsforCQ1,1forCQ2,2forCQ3,14forCQ4,and8for\\nCQ5wereincludedinthequalitativeanalysis(eTable2in Supplement1).Intheprimaryanalysis,the\\nsensitivityandspecificityoftheindexresultsofLLM-assistedscreeningwere1.00(95%CI,\\n0.50-1.00)and0.99(95%CI,0.99-0.99)forCQ1,0.25(95%CI,0.03-0.76)and0.99(95%CI,0.99-\\n1.00)forCQ2,0.50(95%CI,0.12-0.88)and0.99(95%CI,0.99-1.00)forCQ3,0.82(95%CI,0.57-\\n0.94)and0.99(95%CI,0.99-1.00)forCQ4,and1.00(95%CI,0.50-1.00)and0.98(95%CI,\\n0.98-0.99)forCQ5,respectively(Figure 2).Thenumbersoftrue-positive,true-negative,false-\\npositive,andfalse-negativeresultsarelistedineTable2in Supplement1.Meta-analysisshowedthat\\ntheintegratedsensitivityandspecificityvaluesamongthe5CQswere0.75(95%CI,0.43-0.92)and\\n0.99(95%CI,0.99-0.99),respectively(Figure2).\\nSecondary Analysis of the Accuracy of LLM-Assisted Citation Screening'),\n",
       "  Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='[95%CI,14.2–18.6]minutes)(unpaired t test:meandifference,−15.25minutes;95%CI,−17.70to\\n−12.79minutes; P < .001)(eAppendix,eTable3,andeFigure2in Supplement1).\\nPost Hoc Analysis Using the Modified Prompt\\nIntheposthocanalysisusingthemodifiedcommand(eAppendix,eTable4,andeFigure3in\\nSupplement1),theintegratedsensitivityandspecificityvaluesamongthe5CQswere0.89(95%CI,\\n0.74-0.95)and0.98(95%CI,0.97-0.99),respectively( Figure 4).Thenumbersoftrue-positive,\\ntrue-negative,false-positive,andfalse-negativeresultsarelistedineTable5Ain Supplement1.\\nPost Hoc Analysis Using Majority-Vote and Chain-of-Thought Strategies\\nWiththeoriginalpromptandamajority-votestrategy,theintegratedsensitivityandspecificityvalues\\namongthe5CQswere0.75(95%CI,0.43-0.92)and0.99(95%CI,0.98-0.99)intheprimary\\nanalysis(eFigure5andeTable5BinSupplement1).Usingthemodifiedpromptandamajorityvote,\\ntheaggregatesensitivityandspecificityvaluesamongthe5CQswere0.91(95%CI,0.77-0.97)and'),\n",
       "  Document(metadata={'source': '../data/LLM.pdf', 'page': 5}, page_content='0.98(95%CI,0.96-0.99)intheprimaryanalysis(Figure 5;eTable5Cin Supplement1).\\nWiththeoriginalpromptandthechain-of-thoughtstrategy(eFigure8in Supplement1),theinte-\\ngratedsensitivityandspecificityvaluesamongthe5CQswere0.71(95%CI,0.45-0.88)and0.99(95%\\nCI,0.98-0.99)intheprimaryanalysis(eFigure9andeTable5DinSupplement1).Usingthemodified\\npromptandthechain-of-thoughtstrategy,theaggregatesensitivityandspecificityvaluesamongthe5\\nCQswere0.87(95%CI,0.67-0.96)and0.98(95%CI,0.96-0.99)intheprimaryanalysis(eFigure11\\nFigure 4. Post Hoc Analysis for the Primary Analysis Using the Modified Prompt\\n1.00.80.60.40.20\\nSensitivity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n1.00 (0.50-1.00)\\n1.00 (0.33-0.99)\\n0.75 (0.24-0.97)\\n0.88 (0.63-0.97)\\n1.00 (0.50-1.00)\\n0.89 (0.74-0.95)\\nSensitivity \\n(95% CI)\\nRandom- \\neffects model\\nHeterogeneity: I2 = 0%; P = .87\\nSensitivityA\\n1.00.80.60.40.20\\nSpecificity (95% CI)\\nCQ\\n1\\n2\\n3\\n4\\n5\\n0.99 (0.98-0.99)\\n0.98 (0.98-0.99)\\n0.99 (0.98-1.00)\\n0.96 (0.96-0.97)\\n0.97 (0.96-0.98)\\n0.98 (0.97-0.99)\\nSpecificity')],\n",
       " 'answer': 'The study analyzed the sensitivity and specificity of Large Language Model (LLM)-assisted citation screening in various academic journals, including 5 quality control (CQ) codes. The results showed that:\\n\\n- The integrated sensitivity and specificity values among the 5 CQ codes were 0.75 and 0.99 for primary analysis, respectively.\\n- Meta-analysis found similar results: 0.75 for individual CQ codes and 0.99 overall.\\n- Secondary analysis using unpaired t-test compared to primary analysis showed a significant difference in sensitivity (p < .001).\\n- Post hoc analyses using modified prompts, majority-vote, and chain-of-thought strategies also yielded similar results, with integrated values ranging from 0.71 to 0.98 for the different strategies.\\n- The heterogeneity among CQ codes was low (I2 = 0%; p = 0.87), indicating that individual studies have consistent results when using LLM-assisted citation screening.\\n\\nOverall, the study concluded that LLM-assisted citation screening has high sensitivity and specificity across various academic journals, with some variability depending on the specific criteria used in the analysis.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
